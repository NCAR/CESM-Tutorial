{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEFORE BEGINNING THIS EXERCISE** -  Check that your kernel (upper right corner, above) is `NPL 2023b`. This should be the default kernel, but if it is not, click on that button and select `NPL 2023b`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "This activity was developed primarily by Cecile Hannay and Jesse Nusbaumer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "## Exercise 1: CAM-SE output analysis\n",
    "\n",
    "Examples of simple analysis and plotting that can be done with CAM-SE output on the native cubed-sphere grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map(data, lon, lat,):\n",
    "    \"\"\"This function plots data on a Mollweide projection map. \n",
    "    \n",
    "    The data is transformed to the projection using Cartopy's `transform_points` method.\n",
    "\n",
    "    The plot is made by triangulation of the points, producing output very similar to `pcolormesh`,\n",
    "    but with triangles instead of rectangles used to make the image.\n",
    "    \"\"\"\n",
    "    dataproj = ccrs.PlateCarree() # assumes data is lat/lon\n",
    "    plotproj = ccrs.Mollweide()   # output projection \n",
    "    # set up figure / axes object, set to be global, add coastlines\n",
    "    fig, ax = plt.subplots(figsize=(6,3), subplot_kw={'projection':plotproj})\n",
    "    ax.set_global()\n",
    "    ax.coastlines(linewidth=0.2)\n",
    "    # this figures out the transformation between (lon,lat) and the specified projection\n",
    "    tcoords = plotproj.transform_points(dataproj, lon.values, lat.values) # working with the projection\n",
    "    xi=tcoords[:,0] != np.inf  # there can be bad points set to infinity, but we'll ignore them\n",
    "    # print(f\"{xi.shape = } --- Number of False: {np.count_nonzero(~xi)}\")\n",
    "    assert xi.shape[0] == tcoords.shape[0], f\"Something wrong with shapes should be the same: {xi.shape = }, {tcoords.shape = }\"\n",
    "    tc=tcoords[xi,:]\n",
    "    datai=data.values[xi]  # convert to numpy array, then subset\n",
    "    # Use tripcolor --> triangluates the data to make the plot\n",
    "    # rasterized=True reduces the file size (necessary for high-resolution for reasonable file size)\n",
    "    # keep output as \"img\" to make specifying colorbar easy\n",
    "    img = ax.tripcolor(tc[:,0],tc[:,1], datai, shading='gouraud', rasterized=True)\n",
    "    cbar = fig.colorbar(img, ax=ax, shrink=0.4)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "In the following cell, specify the data source.\n",
    "\n",
    "`location_of_hfiles` is a path object that points to the directory where data files should be.\n",
    "`search_pattern` specifies what pattern to look for inside that directory.\n",
    "\n",
    "**SIMPLIFICATION** If you want to just provide a path to a file, simply specify it by commenting (with `#`) the lines above \"# WE need lat and lon\", and replace with:\n",
    "```\n",
    "fils = \"/path/to/your/data/file.nc\"\n",
    "```\n",
    "\n",
    "## Parameters\n",
    "Specify the name of the variable to be analyzed with `variable_name`.\n",
    "\n",
    "To change the units of the variable, specify `scale_factor` and provide the new units string as `units`. Otherwise, just set `scale_factor` and `units`:\n",
    "\n",
    "```\n",
    "scale_factor = 1\n",
    "units = ds[\"variable_name\"].attrs[\"units\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_of_hfiles = Path(\"/glade/campaign/cesm/cesm/tutorial/tutorial_2023_archive/cam-se/\")\n",
    "search_pattern = \"f.cam6_3_112.FMTHIST_v0c.ne30.non-ogw-ubcT-effgw0.7_taubgnd2.5.001.cam.h3.2003-01-01-00000.nc\"\n",
    "\n",
    "fils = sorted(location_of_hfiles.glob(search_pattern))\n",
    "if len(fils) == 1:\n",
    "    ds = xr.open_dataset(fils[0])\n",
    "else:\n",
    "    print(f\"Just so you konw, there are {len(fils)} files about to be loaded.\")\n",
    "    ds = xr.open_mfdataset(fils)\n",
    "\n",
    "# We need lat and lon:\n",
    "lat = ds['lat']\n",
    "lon = ds['lon']\n",
    "\n",
    "# Choose what variables to plot,\n",
    "# in this example we are going to combine the\n",
    "# convective and stratiform precipitation into\n",
    "# a single, total precipitation variable\n",
    "convective_precip_name = \"PRECC\"\n",
    "stratiform_precip_name = \"PRECL\"\n",
    "\n",
    "# If needed, select scale factor and new units:\n",
    "scale_factor = 86400. * 1000. # m/s -> mm/day\n",
    "units = \"mm/day\"\n",
    "\n",
    "cp_data = scale_factor * ds[convective_precip_name]\n",
    "st_data = scale_factor * ds[stratiform_precip_name]\n",
    "cp_data.attrs['units'] = units\n",
    "st_data.attrs['units'] = units\n",
    "\n",
    "# Sum the two precip variables to get total precip\n",
    "data = cp_data + st_data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal averaging\n",
    "# simplest case, just average over time:\n",
    "data_avg = data.mean(dim='time')\n",
    "data_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Global average\n",
    "#\n",
    "data_global_average = data_avg.weighted(ds['area']).mean()\n",
    "print(f\"The area-weighted average of the time-mean data is: {data_global_average.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Regional average using a (logical) rectangle\n",
    "#\n",
    "west_lon = 110.0\n",
    "east_lon = 200.0\n",
    "south_lat = -30.0\n",
    "north_lat = 30.0\n",
    "\n",
    "# To reduce to the region, we need to know which indices of ncol dimension are inside the boundary\n",
    "\n",
    "region_inds = np.argwhere(((lat > south_lat)&(lat < north_lat)&(lon>west_lon)&(lon<east_lon)).values)\n",
    "print(f\"The number of grid columns inside the specified region is {region_inds.shape[0]}\")\n",
    "\n",
    "# get the area associated with each selected column. Note the region_inds array needs to be flattened to use in isel.\n",
    "region_area = ds['area'].isel(ncol=region_inds.flatten()) \n",
    "# get the data in the region:\n",
    "region_data = data_avg.isel(ncol=region_inds.flatten())\n",
    "\n",
    "data_region_average = region_data.weighted(region_area).mean()\n",
    "print(f\"The area-weighted average in thee region [{west_lon}E-{east_lon}E, {south_lat}-{north_lat}] is: {data_region_average.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the map of the time average \n",
    "# using the function defined above.\n",
    "fig1, ax1 = make_map(data_avg, lon, lat,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">   \n",
    "<details>\n",
    "<summary><font face=\"Times New Roman\" color='blue'>Click here for the solution</font></summary><br>\n",
    "\n",
    "![plot example](../../../images/diagnostics/cam/advanced_plot_1.png)\n",
    "\n",
    "*<p style=\"text-align: center;\"> Figure: Plotting solution. </p>*\n",
    "    \n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
